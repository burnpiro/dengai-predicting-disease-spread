{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import functools\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from data_info import *\n",
    "from preprocessing_helpers import *\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_iq_norm = [\n",
    "                'precipitation_amt_mm',\n",
    "                'reanalysis_air_temp_k',\n",
    "                'reanalysis_avg_temp_k',\n",
    "                'reanalysis_dew_point_temp_k',\n",
    "                'reanalysis_max_air_temp_k',\n",
    "                'reanalysis_min_air_temp_k',\n",
    "                'reanalysis_precip_amt_kg_per_m2',\n",
    "                'reanalysis_sat_precip_amt_mm',\n",
    "                'reanalysis_specific_humidity_g_per_kg',\n",
    "                'reanalysis_tdtr_k',\n",
    "                'station_avg_temp_c',\n",
    "                'station_diur_temp_rng_c',\n",
    "                'station_max_temp_c',\n",
    "                'station_min_temp_c',\n",
    "]\n",
    "new_iq_scale = [\n",
    "                 'weekofyear',\n",
    "]\n",
    "\n",
    "extra_iq_cols = [\n",
    "]\n",
    "new_sj_norm = [\n",
    "                'reanalysis_air_temp_k',\n",
    "                'reanalysis_avg_temp_k',\n",
    "                'reanalysis_dew_point_temp_k',\n",
    "                'reanalysis_max_air_temp_k',\n",
    "                'reanalysis_min_air_temp_k',\n",
    "                'reanalysis_precip_amt_kg_per_m2',\n",
    "                'reanalysis_relative_humidity_percent',\n",
    "                'reanalysis_sat_precip_amt_mm',\n",
    "                'reanalysis_specific_humidity_g_per_kg',\n",
    "                'station_avg_temp_c',\n",
    "                'station_diur_temp_rng_c',\n",
    "                'station_max_temp_c',\n",
    "                'station_min_temp_c',\n",
    "]\n",
    "new_sj_scale = [\n",
    "                 'weekofyear',\n",
    "]\n",
    "\n",
    "extra_sj_cols = [\n",
    "]\n",
    "new_iq_cols = [LABEL_COLUMN] + CATEGORICAL_COLUMNS + new_iq_norm + new_iq_scale + extra_iq_cols + [DATETIME_COLUMN]\n",
    "new_iq_cols_no_label = CATEGORICAL_COLUMNS + new_iq_norm + new_iq_scale + extra_iq_cols + [DATETIME_COLUMN]\n",
    "new_sj_cols = [LABEL_COLUMN] + CATEGORICAL_COLUMNS + new_sj_norm + new_sj_scale + extra_sj_cols + [DATETIME_COLUMN]\n",
    "new_sj_cols_no_label = CATEGORICAL_COLUMNS + new_sj_norm + new_sj_scale + extra_sj_cols + [DATETIME_COLUMN]\n",
    "\n",
    "\n",
    "sj_col_size = {\n",
    "    'precipitation_amt_mm': 40,\n",
    "    'reanalysis_air_temp_k': 16,\n",
    "    'reanalysis_avg_temp_k': 15,\n",
    "    'reanalysis_dew_point_temp_k': 39,\n",
    "    'reanalysis_max_air_temp_k': 12,\n",
    "    'reanalysis_min_air_temp_k': 21,\n",
    "    'reanalysis_precip_amt_kg_per_m2': 30,\n",
    "    'reanalysis_relative_humidity_percent': 34,\n",
    "    'reanalysis_sat_precip_amt_mm': 40,\n",
    "    'reanalysis_specific_humidity_g_per_kg': 14,\n",
    "    'reanalysis_tdtr_k': 21,\n",
    "    'station_avg_temp_c': 41,\n",
    "    'station_diur_temp_rng_c': 40,\n",
    "    'station_max_temp_c': 37,\n",
    "    'station_min_temp_c': 26,\n",
    "    'station_precip_mm': 32,\n",
    "    'weekofyear': 3\n",
    "}\n",
    "iq_col_size = {\n",
    "    'precipitation_amt_mm': 33,\n",
    "    'reanalysis_air_temp_k': 10,\n",
    "    'reanalysis_avg_temp_k': 4,\n",
    "    'reanalysis_dew_point_temp_k': 6,\n",
    "    'reanalysis_max_air_temp_k': 41,\n",
    "    'reanalysis_min_air_temp_k': 40,\n",
    "    'reanalysis_precip_amt_kg_per_m2': 3,\n",
    "    'reanalysis_relative_humidity_percent': 7,\n",
    "    'reanalysis_sat_precip_amt_mm': 33,\n",
    "    'reanalysis_specific_humidity_g_per_kg': 26,\n",
    "    'reanalysis_tdtr_k': 34,\n",
    "    'station_avg_temp_c': 40,\n",
    "    'station_diur_temp_rng_c': 26,\n",
    "    'station_max_temp_c': 39,\n",
    "    'station_min_temp_c': 25,\n",
    "    'station_precip_mm':10,\n",
    "    'weekofyear': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reanalysis_air_temp_k',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k',\n",
       " 'reanalysis_precip_amt_kg_per_m2',\n",
       " 'reanalysis_relative_humidity_percent',\n",
       " 'reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'station_avg_temp_c',\n",
       " 'station_diur_temp_rng_c',\n",
       " 'station_max_temp_c',\n",
       " 'station_min_temp_c',\n",
       " 'weekofyear']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_datasets, sj_norm_scale, sj_columns = generate_lstm_data(\n",
    "    train_file, \n",
    "    single_step=True, \n",
    "    history_size=52, \n",
    "    cols=new_sj_cols, \n",
    "    norm_cols=new_sj_norm, \n",
    "    scale_cols=new_sj_scale,\n",
    "    extra_columns=extra_sj_cols,\n",
    "    prepend_with_file=train_file,\n",
    "    train_frac=1.0,\n",
    "    group_by_column=True\n",
    ")\n",
    "sj_train_x, sj_train_y = sj_datasets[0]\n",
    "sj_train_x = np.array(sj_train_x)\n",
    "sj_train_y = np.array(sj_train_y)\n",
    "iq_datasets, iq_norm_scale, iq_columns = generate_lstm_data(\n",
    "    train_file, \n",
    "    single_step=True, \n",
    "    history_size=52, \n",
    "    cols=new_iq_cols, \n",
    "    norm_cols=new_iq_norm, \n",
    "    scale_cols=new_iq_scale,\n",
    "    extra_columns=extra_iq_cols,\n",
    "    prepend_with_file=train_file,\n",
    "    train_frac=1.0,\n",
    "    group_by_column=True\n",
    ")\n",
    "iq_train_x, iq_train_y = iq_datasets[1]\n",
    "iq_train_x = np.array(iq_train_x)\n",
    "iq_train_y = np.array(iq_train_y)\n",
    "sj_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.28415113, -0.77349674, -0.31767771, -0.1531716 ,  0.27180253,\n",
       "        0.36091001,  0.02275855,  0.33006511,  0.31978348,  0.78017211,\n",
       "        0.26723291,  0.3906125 ,  0.30378983,  0.54712179,  0.96981111,\n",
       "        0.62366283,  0.92297256,  0.75161203,  1.08062425,  1.19600701,\n",
       "        0.54255217,  0.9983712 ,  1.27711767,  0.54255217,  0.01361932,\n",
       "       -0.22057341,  0.43859345,  0.63508686,  0.9366814 ,  0.26609051,\n",
       "       -0.75179107, -0.50845911, -0.78035116, -0.70495252, -0.91172757,\n",
       "       -1.69427401, -1.20304048, -1.4041035 , -1.03510715, -0.90715795,\n",
       "       -1.15048991, -1.83478965, -1.41095793, -1.3378441 , -1.12078742,\n",
       "       -1.39724908, -1.41666994, -1.36640419, -1.6908468 , -1.44408763,\n",
       "       -1.51491665, -0.88316748])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train_x[53][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.36640419, -1.6908468 , -1.44408763, -1.51491665, -0.88316748])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train_x[53][0][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train_y[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 368)\n",
      "(520, 363)\n"
     ]
    }
   ],
   "source": [
    "trimed_sj_x = []\n",
    "trimed_iq_x = []\n",
    "\n",
    "def trim_data(data, columns, size_cols):\n",
    "    trimed_data = []\n",
    "    for row_i in range(data.shape[0]):\n",
    "        new_row = []\n",
    "        for col_i, col in enumerate(columns):\n",
    "            new_row = np.concatenate((new_row, data[row_i][col_i][-size_cols[col]:]), axis=None)\n",
    "\n",
    "        trimed_data.append(new_row)\n",
    "    return np.array(trimed_data)\n",
    "    \n",
    "trimed_sj_x = trim_data(sj_train_x, sj_columns, sj_col_size)\n",
    "trimed_iq_x = trim_data(iq_train_x, iq_columns, iq_col_size)\n",
    "\n",
    "print(trimed_sj_x.shape)\n",
    "print(trimed_iq_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 500\n",
    "train_sj_data_single = tf.data.Dataset.from_tensor_slices((trimed_sj_x, sj_train_y))\n",
    "train_sj_data_single = train_sj_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat(10)\n",
    "\n",
    "# val_sj_data_single = tf.data.Dataset.from_tensor_slices((sj_val_x, sj_val_y))\n",
    "# val_sj_data_single = val_sj_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network with \n",
    "def build_model(optimizer = None, nodes=256, input_shape=trimed_sj_x.shape[-1]):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=input_shape),\n",
    "    tf.keras.layers.Dense(nodes, activation='selu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(nodes/2, activation='selu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  if not optimizer:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.9999, amsgrad=False)\n",
    "\n",
    "  model.compile(loss='mae',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200 steps\n",
      "Epoch 1/40\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 25.3911 - mae: 25.4540 - mse: 2630.0166\n",
      "Epoch 2/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 20.8509 - mae: 20.8911 - mse: 1609.3301\n",
      "Epoch 3/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 19.0851 - mae: 19.1081 - mse: 1256.3760\n",
      "Epoch 4/40\n",
      "196/200 [============================>.] - ETA: 0s - loss: 17.9434 - mae: 17.9430 - mse: 1131.4384\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 17.9678 - mae: 17.9676 - mse: 1130.3939\n",
      "Epoch 5/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 16.1065 - mae: 16.1336 - mse: 901.7075\n",
      "Epoch 6/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 15.7616 - mae: 15.8051 - mse: 872.0537\n",
      "Epoch 7/40\n",
      "192/200 [===========================>..] - ETA: 0s - loss: 15.2995 - mae: 15.2136 - mse: 840.7195\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 15.3142 - mae: 15.2323 - mse: 836.2635\n",
      "Epoch 8/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 14.3775 - mae: 14.3880 - mse: 685.4814\n",
      "Epoch 9/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 13.3446 - mae: 13.3694 - mse: 546.2976\n",
      "Epoch 10/40\n",
      "191/200 [===========================>..] - ETA: 0s - loss: 13.5767 - mae: 13.6027 - mse: 604.2989\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0051199994981288915.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 13.4874 - mae: 13.5114 - mse: 590.4205\n",
      "Epoch 11/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 12.6918 - mae: 12.6798 - mse: 490.5443\n",
      "Epoch 12/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 12.0019 - mae: 12.0257 - mse: 457.4622\n",
      "Epoch 13/40\n",
      "197/200 [============================>.] - ETA: 0s - loss: 12.0940 - mae: 12.1126 - mse: 473.1556\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.004095999523997307.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 12.1487 - mae: 12.1675 - mse: 482.9854\n",
      "Epoch 14/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 11.4040 - mae: 11.4082 - mse: 402.0927\n",
      "Epoch 15/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 11.1858 - mae: 11.1846 - mse: 368.6043\n",
      "Epoch 16/40\n",
      "197/200 [============================>.] - ETA: 0s - loss: 11.3991 - mae: 11.4347 - mse: 406.0902\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0032767996191978457.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 11.4521 - mae: 11.4875 - mse: 412.4932\n",
      "Epoch 17/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 10.5719 - mae: 10.5825 - mse: 325.1682\n",
      "Epoch 18/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 10.6911 - mae: 10.6745 - mse: 365.4261\n",
      "Epoch 19/40\n",
      "199/200 [============================>.] - ETA: 0s - loss: 10.5450 - mae: 10.5503 - mse: 355.2982\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0026214396581053737.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 10.5581 - mae: 10.5634 - mse: 357.2647\n",
      "Epoch 20/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 10.0714 - mae: 10.0563 - mse: 316.0736\n",
      "Epoch 21/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 9.9549 - mae: 9.9760 - mse: 317.6318\n",
      "Epoch 22/40\n",
      "195/200 [============================>.] - ETA: 0s - loss: 9.6122 - mae: 9.6197 - mse: 272.6069\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0020971518009901048.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 9.6380 - mae: 9.6455 - mse: 273.4172\n",
      "Epoch 23/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 9.3906 - mae: 9.3770 - mse: 305.6332\n",
      "Epoch 24/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 9.4696 - mae: 9.4651 - mse: 322.0454\n",
      "Epoch 25/40\n",
      "193/200 [===========================>..] - ETA: 0s - loss: 9.1087 - mae: 9.0867 - mse: 259.4871\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0016777213662862779.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 9.1291 - mae: 9.1081 - mse: 257.4643\n",
      "Epoch 26/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.9722 - mae: 8.9676 - mse: 247.0614\n",
      "Epoch 27/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.8440 - mae: 8.8758 - mse: 257.8858\n",
      "Epoch 28/40\n",
      "195/200 [============================>.] - ETA: 0s - loss: 8.4888 - mae: 8.5098 - mse: 204.7547\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0013421771116554739.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.4770 - mae: 8.4972 - mse: 206.8525\n",
      "Epoch 29/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.5303 - mae: 8.5656 - mse: 238.9109\n",
      "Epoch 30/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.5322 - mae: 8.5545 - mse: 246.2475\n",
      "Epoch 31/40\n",
      "198/200 [============================>.] - ETA: 0s - loss: 8.3030 - mae: 8.3154 - mse: 219.1606\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.001073741726577282.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.2960 - mae: 8.3082 - mse: 218.1558\n",
      "Epoch 32/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.2801 - mae: 8.2664 - mse: 226.7064\n",
      "Epoch 33/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 7.7257 - mae: 7.7338 - mse: 185.5170\n",
      "Epoch 34/40\n",
      "197/200 [============================>.] - ETA: 0s - loss: 8.1271 - mae: 8.1496 - mse: 240.2151\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0008589933626353742.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 8.1339 - mae: 8.1560 - mse: 239.4606\n",
      "Epoch 35/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 7.7908 - mae: 7.7965 - mse: 209.9137\n",
      "Epoch 36/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 7.7377 - mae: 7.7445 - mse: 175.9112\n",
      "Epoch 37/40\n",
      "189/200 [===========================>..] - ETA: 0s - loss: 7.6855 - mae: 7.6903 - mse: 177.8420\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0006871947087347508.\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 7.6551 - mae: 7.6593 - mse: 176.6685\n",
      "Epoch 38/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 7.7306 - mae: 7.7441 - mse: 204.2079\n",
      "Epoch 39/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 7.6654 - mae: 7.6736 - mse: 198.1789\n",
      "Epoch 40/40\n",
      "196/200 [============================>.] - ETA: 0s - loss: 7.5814 - mae: 7.5944 - mse: 204.6808\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005497557576745749.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 7.5507 - mae: 7.5632 - mse: 202.1385\n"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs/fit/lstm\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# create model\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.01, nesterov=False, name='SGD')\n",
    "\n",
    "\n",
    "# Train the Model.\n",
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 40\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.9999, amsgrad=False)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"mae\", factor=0.8, patience=3, min_lr=1e-6, verbose=1,\n",
    "                                                     mode=\"max\")\n",
    "\n",
    "train_sj_data_single = tf.data.Dataset.from_tensor_slices((trimed_sj_x, sj_train_y))\n",
    "train_sj_data_single = train_sj_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.01, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop'\n",
    ")\n",
    "sj_model = build_model(optimizer=opt, nodes=400)\n",
    "history = sj_model.fit(\n",
    "    train_sj_data_single,\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=EVALUATION_INTERVAL,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200 steps\n",
      "Epoch 1/40\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 7.4685 - mae: 7.5264 - mse: 147.8833\n",
      "Epoch 2/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 6.3087 - mae: 6.3590 - mse: 119.5104\n",
      "Epoch 3/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 6.1212 - mae: 6.1714 - mse: 119.4287\n",
      "Epoch 4/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 6.0146 - mae: 6.0686 - mse: 119.0130\n",
      "Epoch 5/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.9251 - mae: 5.9755 - mse: 115.9475\n",
      "Epoch 6/40\n",
      "193/200 [===========================>..] - ETA: 0s - loss: 5.7509 - mae: 5.8048 - mse: 116.9585\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.7713 - mae: 5.8234 - mse: 115.7584\n",
      "Epoch 7/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.6937 - mae: 5.7515 - mse: 113.7491\n",
      "Epoch 8/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.6304 - mae: 5.6868 - mse: 116.8404\n",
      "Epoch 9/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.4949 - mae: 5.5466 - mse: 107.6227\n",
      "Epoch 10/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.4807 - mae: 5.5326 - mse: 106.8529\n",
      "Epoch 11/40\n",
      "197/200 [============================>.] - ETA: 0s - loss: 5.2100 - mae: 5.2612 - mse: 99.2773\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 5.1800 - mae: 5.2297 - mse: 98.0621\n",
      "Epoch 12/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 4.9758 - mae: 5.0187 - mse: 91.8359\n",
      "Epoch 13/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 4.9197 - mae: 4.9665 - mse: 90.1285\n",
      "Epoch 14/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 4.6261 - mae: 4.6703 - mse: 80.3703\n",
      "Epoch 15/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 4.5659 - mae: 4.6055 - mse: 77.5713\n",
      "Epoch 16/40\n",
      "192/200 [===========================>..] - ETA: 0s - loss: 4.3784 - mae: 4.4220 - mse: 71.5478\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 4.3873 - mae: 4.4290 - mse: 71.3449\n",
      "Epoch 17/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 4.3105 - mae: 4.3596 - mse: 69.9772\n",
      "Epoch 18/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 4.1257 - mae: 4.1648 - mse: 64.6137\n",
      "Epoch 19/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.9950 - mae: 4.0316 - mse: 60.8231\n",
      "Epoch 20/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.9563 - mae: 3.9911 - mse: 59.2244\n",
      "Epoch 21/40\n",
      "196/200 [============================>.] - ETA: 0s - loss: 3.8079 - mae: 3.8402 - mse: 55.0913\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.8745 - mae: 3.9069 - mse: 55.9017\n",
      "Epoch 22/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.6644 - mae: 3.6971 - mse: 50.4065\n",
      "Epoch 23/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.6203 - mae: 3.6488 - mse: 51.7959\n",
      "Epoch 24/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.5155 - mae: 3.5464 - mse: 50.2440\n",
      "Epoch 25/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.4624 - mae: 3.4882 - mse: 46.8766\n",
      "Epoch 26/40\n",
      "195/200 [============================>.] - ETA: 0s - loss: 3.3994 - mae: 3.4249 - mse: 41.9512\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.4324 - mae: 3.4577 - mse: 44.0138\n",
      "Epoch 27/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.2858 - mae: 3.3133 - mse: 43.3566\n",
      "Epoch 28/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 3.2228 - mae: 3.2504 - mse: 41.8401\n",
      "Epoch 29/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 3.2265 - mae: 3.2491 - mse: 40.6955\n",
      "Epoch 30/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 3.1445 - mae: 3.1650 - mse: 38.4862\n",
      "Epoch 31/40\n",
      "198/200 [============================>.] - ETA: 0s - loss: 3.0768 - mae: 3.1033 - mse: 38.7598\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 3.0844 - mae: 3.1106 - mse: 38.6728\n",
      "Epoch 32/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 3.0169 - mae: 3.0401 - mse: 36.0616\n",
      "Epoch 33/40\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.9429 - mae: 2.9668 - mse: 36.0580\n",
      "Epoch 34/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.7962 - mae: 2.8123 - mse: 32.1144\n",
      "Epoch 35/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.8030 - mae: 2.8236 - mse: 32.5504\n",
      "Epoch 36/40\n",
      "193/200 [===========================>..] - ETA: 0s - loss: 2.8534 - mae: 2.8676 - mse: 31.4455\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.8069 - mae: 2.8226 - mse: 30.6177\n",
      "Epoch 37/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.7511 - mae: 2.7706 - mse: 31.5878\n",
      "Epoch 38/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.6261 - mae: 2.6468 - mse: 28.4199\n",
      "Epoch 39/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.6590 - mae: 2.6794 - mse: 30.2487\n",
      "Epoch 40/40\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.6318 - mae: 2.6513 - mse: 28.7361\n"
     ]
    }
   ],
   "source": [
    "train_iq_data_single = tf.data.Dataset.from_tensor_slices((trimed_iq_x, iq_train_y))\n",
    "train_iq_data_single = train_iq_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "EPOCHS = 40\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.9999, amsgrad=False)\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop'\n",
    ")\n",
    "iq_model = build_model(optimizer=opt, nodes=400, input_shape=trimed_iq_x.shape[-1])\n",
    "train_iq_data_single = tf.data.Dataset.from_tensor_slices((trimed_iq_x, iq_train_y))\n",
    "train_iq_data_single = train_iq_data_single.cache().batch(BATCH_SIZE).repeat()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"mae\", factor=0.8, patience=5, min_lr=1e-6, verbose=1,\n",
    "                                                     mode=\"max\")\n",
    "history = iq_model.fit(\n",
    "    train_iq_data_single,\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=EVALUATION_INTERVAL,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 368)\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "file = train_file\n",
    "file = test_file\n",
    "\n",
    "org_sj_test_data, test_scale, sj_columns = generate_lstm_data(\n",
    "    file, history_size=52, \n",
    "    cols=new_sj_cols_no_label, \n",
    "    norm_cols=new_sj_norm, \n",
    "    scale_cols=new_sj_scale, \n",
    "    single_step=True, \n",
    "    train_frac=1.0, train_scale=sj_norm_scale, \n",
    "    prepend_with_file=train_file,\n",
    "    extra_columns=extra_sj_cols,\n",
    "    group_by_column=True\n",
    ")\n",
    "org_iq_test_data, test_scale, iq_columns = generate_lstm_data(\n",
    "    file, history_size=52, \n",
    "    cols=new_iq_cols_no_label, \n",
    "    norm_cols=new_iq_norm, \n",
    "    scale_cols=new_iq_scale, \n",
    "    single_step=True, \n",
    "    train_frac=1.0, train_scale=iq_norm_scale, \n",
    "    prepend_with_file=train_file,\n",
    "    extra_columns=extra_iq_cols,\n",
    "    group_by_column=True\n",
    ")\n",
    "sj_test_x, sj_test_y = org_sj_test_data[0]\n",
    "sj_test_x = np.array(sj_test_x)\n",
    "sj_test_y = np.array(sj_test_y)\n",
    "iq_test_x, iq_test_y = org_iq_test_data[1]\n",
    "iq_test_x = np.array(iq_test_x)\n",
    "iq_test_y = np.array(iq_test_y)\n",
    "trimed_test_sj_x = trim_data(sj_test_x, sj_columns, sj_col_size)\n",
    "trimed_test_iq_x = trim_data(iq_test_x, iq_columns, iq_col_size)\n",
    "sj_test_set = tf.data.Dataset.from_tensor_slices((trimed_test_sj_x, sj_test_y)).batch(len(sj_test_y))\n",
    "print(trimed_test_sj_x.shape)\n",
    "\n",
    "sj_pred = []\n",
    "for x, y in sj_test_set.take(1):\n",
    "    predictions = sj_model.predict(x)\n",
    "    sj_pred = predictions.flatten()\n",
    "    print(len(predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "iq_test_set = tf.data.Dataset.from_tensor_slices((trimed_test_iq_x, iq_test_y)).batch(len(iq_test_y))\n",
    "iq_pred = []\n",
    "for x, y in iq_test_set.take(1):\n",
    "    predictions = iq_model.predict(x)\n",
    "    iq_pred = predictions.flatten()\n",
    "    print(len(predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "asas\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_helpers import export_test_to_csv\n",
    "preds = np.concatenate((sj_pred, iq_pred), axis=None)\n",
    "export_test_to_csv(predictions=preds,path=file, prefix='test' if file == test_file else 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Current Ranking (baseline)\n",
    "Image(\"img/current-26-05.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "# https://tensorboard.dev/experiment/rsdMubj0S165iOdLmbd13A/#scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sj_model.save('models/sj_model_17.57MAP.h5') \n",
    "# iq_model.save('models/iq_model_17.57MAP.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
